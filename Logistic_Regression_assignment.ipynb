{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**1. What is Simple Linear Regression (SLR)? Explain its purpose ?**\n",
        "\n",
        ">  Simple Linear Regression (SLR) is a statistical and machine learning technique used to model the relationship between two variables such as-\n",
        "one independent variable(X) and one dependent variable(Y) — by fitting a straight line to the data points that shows a linear relationship.\n",
        "\n",
        "> **Assumptions of Simple Linear Regression:-**\n",
        ">- Linear relationship between X and Y.\n",
        ">- Residuals or errors are normally distributed.\n",
        ">- Observations are independent.\n",
        ">- No or minimal outliers.\n",
        "\n",
        ">** Purpose of Simple Linear Regressoin:-**\n",
        ">- To predict the value of a dependent variable based on the value of indenpendent variable. Example - predict the price of house based on the number of rooms availability.\n",
        ">- Helps for identify the pattern and trend analysis. Example - trends growth overtime.\n",
        ">- Used to forecast future values based on past trends. Example - predict the future demands.\n",
        ">- o find and quantify the strength and direction of the relationship between X and Y. If Beta 1 is positive - direct relationship and Beta 1 is negative - inverse relationship.\n",
        ">- Businesses, economists, and scientists use SLR for data-driven decision-making and to identify key influencing factors.\n",
        "\n",
        "> **Conclusion:-**\n",
        ">> Evidence for its effectiveness comes from its widespread use in real-world applications, such as in finance (stock price predictions) or medicine, supported by statistical theory. However, it assumes linearity, no multicollinearity, and independence of errors, which must be checked to avoid misleading results.\n",
        "\n"
      ],
      "metadata": {
        "id": "kMmeKUnU3d17"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. **What are the key assumptions of Simple Linear Regression ?**\n",
        "\n",
        "\n",
        "> Simple Linear Regression is a statistical method used to understand the relationship between one independent variable (X) and one dependent variable (Y).  \n",
        "> For this method to give accurate and meaningful results, certain key assumptions must be satisfied.  \n",
        "These assumptions ensure that the model fits the data correctly and that the conclusions drawn from it are valid.\n",
        "\n",
        "> (i) **Linearity:-**\n",
        ">- There should be a linear relationship between the independent variable (X) and the dependent variable (Y).  \n",
        ">- This means that the change in Y is proportional to the change in X. If the relationship is not linear, the regression line will not represent the data properly.\n",
        "\n",
        "> (ii) **Independence of Observations:-**\n",
        ">- The data points or observations must be independent of each other. One\n",
        "observation should not affect another. If observations are dependent, the model’s results become unreliable. Example: each student’s marks in a class should be recorded independently, not influenced by another student’s marks.\n",
        "\n",
        "> (iii) **Homoscedasticity (Equal Variance of Errors):-**\n",
        ">- The variance of errors (difference between actual and predicted values) should remain **constant** across all values of X.  \n",
        ">- In simple words, the errors should be spread out evenly throughout the data.  \n",
        "\n",
        "> **(iv) Normal Distribution of Errors:-**\n",
        ">- The errors or residuals (the gap between actual and predicted Y values) should follow a normal (bell-shaped) distribution.  \n",
        "This helps ensure that predictions and hypothesis tests made using the model are accurate and valid.\n",
        "\n",
        "> **(v) No Major Outliers:-**\n",
        ">- The dataset should not contain extreme or unusual values that can pull the regression line in one direction.  \n",
        "Outliers can distort the slope and intercept, giving a wrong relationship between X and Y.\n",
        "\n",
        ">(vi) **Accurate Measurement of the Independent Variable:-**\n",
        ">- The independent variable (X) should be **measured accurately**.  \n",
        "If X contains errors or is recorded wrongly, the entire regression model may give false predictions.\n",
        "\n",
        "> **Conclusion:-**\n",
        "\n",
        ">> Simple Linear Regression depends on several important assumptions that ensure the model is correct and trustworthy. When these assumptions are satisfied — linearity, independence, equal variance, normal errors, and absence of outliers — the regression line gives a clear and reliable understanding of how one variable affects another.\n",
        "\n"
      ],
      "metadata": {
        "id": "882TEjgT8Sqz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ">3. **Write the mathematical equation for a simple linear regression model and\n",
        "explain each term ?**\n",
        "\n",
        "> Simple Linear Regression is a method that shows how a dependent variable (Y) changes with respect to an independent variable (X). It is represented by a straight-line equation that helps to predict the value of Y from a given value of X.\n",
        "\n",
        "> **Mathematical Equation of Simple Linear Regression Model:-**\n",
        ">- Y = β₀ + β₁X + ε\n",
        "\n",
        "> **Explanation of Each Term:-**\n",
        "\n",
        "> **(i) Y (Dependent Variable):-**\n",
        ">- This is the variable we want to predict or explain.  \n",
        ">- Its value depends on the independent variable (X).  \n",
        ">- Example: predicting salary (Y) based on years of experience (X).\n",
        "\n",
        "> **(ii) X (Independent Variable):-**\n",
        ">- This is the input or predictor variable used to estimate the value of Y.  \n",
        ">- Example: years of experience, temperature, age, etc.\n",
        "\n",
        "> **(iii) β₀ (Beta Zero or Intercept):-**\n",
        ">- It represents the value of Y when X = 0.  \n",
        ">- In other words, it is the point where the regression line crosses the Y-axis.\n",
        "\n",
        "(iv) β₁ (Beta One or Slope):-\n",
        ">- It shows how much Y changes when X increases by one unit.  \n",
        ">- If β₁ is positive → Y increases with X.  \n",
        ">- If β₁ is negative → Y decreases with X.\n",
        "\n",
        "> **Conclusion:-**\n",
        "\n",
        ">> The equation Y = β₀ + β₁X + ε forms the foundation of Simple Linear Regression. It helps in predicting the dependent variable (Y) using one independent variable (X) by fitting the best straight line that minimizes the error between actual and predicted values.\n"
      ],
      "metadata": {
        "id": "jW8klMwi_2fv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4. Provide a real-world example where simple linear regression can be applied ?**\n",
        "\n",
        "> Simple Linear Regression is a statistical technique used to model the\n",
        "relationship between one independent variable (X) and one dependent\n",
        "variable (Y) using a straight line that shows the linear relationship. The goal of Simple Linear Regression is to find the best-fit line that minimizes\n",
        "the difference between actual and predicted values of Y.\n",
        "\n",
        "> It helps in predicting the value of Y based on X.\n",
        "\n",
        ">** The general equation is:**\n",
        "    Y = b0 + b1 * X\n",
        "\n",
        "> **where:**\n",
        ">-  b0 = intercept\n",
        ">-  b1 = slope\n",
        "\n",
        "> **Real World Example:-**\n",
        "\n",
        "> In the real world, simple linear regression can be used to predict\n",
        "the price of a house based on its size (in square feet).\n",
        "\n",
        ">- For example:\n",
        "    - X = Size of the house (in sq. ft)\n",
        "    - Y = Price of the house (in lakhs of ₹)\n",
        "\n",
        "> As house size increases, price generally increases — showing a linear relationship.\n",
        "\n",
        "> **Conclusion:-**\n",
        "\n",
        ">> Simple Linear Regression is one of the most fundamental and widely used\n",
        "statistical techniques in data science and business analytics.\n",
        "Through the example of predicting house prices based on house size, we can see how this model helps in understanding and quantifying the relationship between two variables.\n",
        ">> It allows organizations, businesses, and researchers to make predictions,\n",
        "analyze trends, and support decision-making using real-world data."
      ],
      "metadata": {
        "id": "L1Vlsbxzul68"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**5. What is the method of least squares in linear regression ?**\n",
        "\n",
        "> The Method of Least Squares is a statistical technique used in linear regression to find the best-fitting line through a set of data points.\n",
        "\n",
        "> It works by minimizing the sum of the squared differences (errors)\n",
        "between the actual values (Y) and the predicted values (Ŷ) from the line.\n",
        "\n",
        "> **For simple linear regression:**\n",
        "\n",
        ">-  Y = b0 + b1*X\n",
        "\n",
        "Data: X = [1,2,3,4,5], Y = [2,3,5,4,6]\n",
        "\n",
        "Using Least Squares:\n",
        "    X̄ = 3, Ȳ = 4\n",
        "    b1 = 0.9, b0 = 1.3\n",
        "Regression line: Ŷ = 1.3 + 0.9X\n",
        "\n",
        "This line minimizes the total squared error** between actual and predicted values.\n",
        "\n",
        "> **Conclusion:-**\n",
        "\n",
        ">> The Method of Least Squares is used to find the most accurate regression line.\n",
        "It ensures that the predicted values are as close as possible to actual data,\n",
        "making it fundamental in regression analysis, prediction, and data interpretation.\n",
        "\n"
      ],
      "metadata": {
        "id": "tLUc-78bx3vH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**6. What is Logistic Regression? How does it differ from Linear Regression ?**\n",
        "\n",
        "> Logistic Regression is a supervised machine learning algorithm used for classification problems, where the goal is to predict categorical outcomes such as Yes/No, True/False, or Pass/Fail. Unlike Linear Regression, which predicts numerical values, Logistic Regression predicts the probability of an event occurring and assigns it to a class based on a threshold.\n",
        "\n",
        "> **Purpose:-**\n",
        "> The main purpose of Logistic Regression is to determine the likelihood of a certain outcome and make decisions based on probabilities. For example, it can predict whether a student will pass or fail an exam, whether an email is spam, or whether a customer will buy a product.\n",
        "\n",
        "> **Working Principle:-**\n",
        "> Logistic Regression uses input features to estimate the probability of belonging to a specific class. It then classifies the outcome into categories using a decision threshold (commonly 0.5). If the probability is greater than or equal to the threshold, the data is assigned to one class; otherwise, it is assigned to the other class.\n",
        "\n",
        "> **Real-World Example:-**\n",
        "A practical example of Logistic Regression is predicting whether a student will pass or fail based on hours of study. The model estimates the probability of passing. If the probability is high (above 0.5), the student is predicted to pass; if it is low, the student is predicted to fail. Logistic Regression is also widely used in spam detection, medical diagnosis, credit approval, and customer behavior prediction.\n",
        "\n",
        "> **Conclusion:-**\n",
        ">> Logistic Regression is a fundamental and widely used classification technique in statistics and machine learning. Unlike Linear Regression, which predicts continuous outcomes, Logistic Regression predicts probabilities and classifies outcomes into categories. Its applications span many real-world problems such as medical diagnosis, fraud detection, spam filtering, and student performance prediction. Understanding Logistic Regression is essential for solving classification problems and making data-driven decisions."
      ],
      "metadata": {
        "id": "8hB_3t-3zPRL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**7. Name and briefly describe three common evaluation metrics for regression\n",
        "models ?**\n",
        "\n",
        "\n",
        "> **Three Common Evaluation Metrics for Regression Models are:-**\n",
        "\n",
        "> **(i) Mean Absolute Error (MAE):-**\n",
        "\n",
        ">- Description: MAE measures the average of the absolute differences between the predicted values and the actual values.\n",
        ">- Interpretation: It shows how far predictions are from the true values on average. Lower MAE indicates better model performance.\n",
        ">- Use: Simple to calculate and easy to understand; useful when all errors are equally important.\n",
        "\n",
        "> **Mean Squared Error (MSE):-**\n",
        "\n",
        ">- Description: MSE calculates the average of the squared differences between >- predicted and actual values.\n",
        ">- Interpretation: By squaring the errors, MSE penalizes larger errors more than smaller ones, making it sensitive to outliers. Lower MSE indicates better performance.\n",
        ">- Use: Widely used in machine learning and statistics for model optimization.\n",
        "\n",
        "> **R-squared (Coefficient of Determination):-**\n",
        "\n",
        ">- Description: R-squared measures the proportion of variance in the dependent variable that is explained by the independent variable(s) in the model.\n",
        ">- Interpretation: Ranges from 0 to 1. Higher values (closer to 1) indicate that the model explains most of the variation in the data.\n",
        ">- Use: Helps evaluate how well the regression model fits the data.\n",
        "\n",
        "> **Conclusion:-**\n",
        "\n",
        ">> MAE, MSE, and R-squared are commonly used metrics to evaluate regression models. MAE shows the average error, MSE gives more weight to large errors, and R-squared indicates how well the model explains the variation in the data. Together, they help us understand the accuracy and performance of a regression model."
      ],
      "metadata": {
        "id": "g46bpkkd16Qb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**8. What is the purpose of the R-squared metric in regression analysis?**\n",
        "\n",
        "> In regression analysis, we predict a continuous dependent variable using one or more independent variables. To check how well the model performs, we use evaluation metrics. These metrics measure the accuracy of predictions and help us understand the model's goodness of fit.\n",
        "\n",
        "> **Purpose of R-squared in Regression Analysis:-**\n",
        "\n",
        ">- R-squared, also called the coefficient of determination, measures how well the independent variables explain the variation in the dependent variable.\n",
        "\n",
        ">- It indicates the proportion of the total variation in the dependent variable that is explained by the model.\n",
        "\n",
        ">- Its value ranges from 0 to 1:\n",
        "\n",
        ">- Closer to 1 → model explains most of the variation (good fit)\n",
        "\n",
        ">- Closer to 0 → model explains very little (poor fit)\n",
        "\n",
        ">- In short: R-squared helps to evaluate the goodness of fit of a regression model.\n",
        "\n",
        "> **Conclusion:-**\n",
        "\n",
        ">> R-squared shows how well a regression model fits the data. A higher R-squared means the model explains more of the variation in the dependent variable. In the real world this metrics is very helpful."
      ],
      "metadata": {
        "id": "HFEUJ55A3c-y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#9. Write Python code to fit a simple linear regression model using scikit-learn and print the slope and intercept ?\n",
        "\n",
        "#random datasets for model\n",
        "from sklearn.datasets import make_regression\n",
        "x, y = make_regression(n_samples = 1000, n_features = 1, noise = 10)\n",
        "\n",
        "#train test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.30, random_state = 42)\n",
        "\n",
        "#fit the model\n",
        "from sklearn.linear_model import LinearRegression\n",
        "model = LinearRegression()\n",
        "model.fit(x_train, y_train)\n",
        "\n",
        "#coefficient and intercept \\\n",
        "print(\"model coefficient:\", model.coef_)\n",
        "print(\"intercept:\", model.intercept_)"
      ],
      "metadata": {
        "id": "hpn9X5qzQOrZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e360b05-2b0d-47a3-f19c-941145695945"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "model coefficient: [56.93965018]\n",
            "intercept: 0.08850686112385708\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**10. How do you interpret the coefficients in a simple linear regression model ?**\n",
        "\n",
        "> Simple linear regression is a method used to model the relationship between a dependent variable (y) and a single independent variable (X). The model fits a straight line to the data and can be represented by the equation y=mX+c, where\n",
        "m is the slope (coefficient) and c is the intercept. These coefficients help us understand how the independent variable affects the target variable.\n",
        "\n",
        "> **Coefficient:-**\n",
        "\n",
        "> The slope, or coefficient, represents the amount by which the dependent variable changes for a one-unit change in the independent variable. A positive slope indicates that as X increases, y also increases, whereas a negative slope shows that y decreases as X increases. The slope essentially measures the strength and direction of the relationship between X and y.\n",
        "\n",
        "> **Intercept:-**\n",
        "\n",
        "> The intercept is the value of y when X is zero. It represents the starting point of the regression line on the y-axis. While sometimes it may not have a practical interpretation if X = 0 is outside the data range, it is important for defining the position of the regression line.\n",
        "\n",
        "> **Example:-**\n",
        "\n",
        "> Predicting Exam Marks from Hours Studied:-\n",
        "\n",
        "> Equation of the model:\n",
        "\n",
        ">- Marks=5*Hours_Studied+30\n",
        "\n",
        "> Slope (coefficient = 5):\n",
        "\n",
        ">- Each additional hour studied increases the marks by 5.\n",
        ">- Positive slope → more study hours → higher marks.\n",
        "\n",
        "> Intercept (c = 30):_\n",
        "\n",
        ">- If a student studies 0 hours, expected marks = 30.\n",
        ">- Represents the starting value of the regression line.\n",
        "\n",
        "> Interpretation of relationship:-\n",
        "\n",
        ">- Strong positive linear relationship between hours studied and marks obtained.\n",
        ">- Slope shows the rate of change; intercept shows baseline performance.\n",
        "\n",
        "> Prediction example:\n",
        "\n",
        ">- If a student studies 4 hours:\n",
        "\n",
        ">- Marks=5*4+30=50\n",
        "\n",
        ">- The model predicts 50 marks.\n"
      ],
      "metadata": {
        "id": "WQChTZ-7UZup"
      }
    }
  ]
}